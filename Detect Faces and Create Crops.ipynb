{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sohaib/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from scipy import misc\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import argparse\n",
    "import facenet\n",
    "import detect_face\n",
    "import os\n",
    "from os.path import join as pjoin\n",
    "import sys\n",
    "import time\n",
    "import copy\n",
    "import math\n",
    "import pickle\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.externals import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "from PIL import ImageDraw, ImageFont\n",
    "from matplotlib import patches, patheffects\n",
    "import pdb\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_img(im, figsize=None, ax=None):\n",
    "    if not ax: fig,ax = plt.subplots(figsize=figsize)\n",
    "    ax.imshow(im)\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    \n",
    "    return ax\n",
    "\n",
    "def draw_outline(o, lw):\n",
    "    o.set_path_effects([patheffects.Stroke(linewidth=lw, foreground='black'), patheffects.Normal()])\n",
    "\n",
    "def draw_rect(ax, b):\n",
    "    patch = ax.add_patch(patches.Rectangle(b[:2], *b[-2:], fill=False, edgecolor='white', lw=2))\n",
    "    \n",
    "def draw_text(ax, xy, txt, sz=14):\n",
    "    text = ax.text(*xy, txt, vericalalignment='top', color='white', fontsize=sz, weight='bold')\n",
    "    draw_outline(text, 1)\n",
    "    \n",
    "def bb_hw(b):\n",
    "    return np.array([b[0], b[1], b[2]-b[0]+1, b[3]-b[1]+1])\n",
    "\n",
    "def crop(image,i):\n",
    "    padding = 35\n",
    "    b = bb_hw(bounding_boxes[i])\n",
    "\n",
    "    x0 = int(b[0])-padding\n",
    "    x0 = 0 if x0<0 else x0\n",
    "\n",
    "    y0 = int(b[1])-padding\n",
    "    y0 = 0 if y0<0 else y0\n",
    "\n",
    "    width = int(b[2])+padding\n",
    "    width = image.shape[0] if (width>image.shape[0]) else width\n",
    "\n",
    "    height = int(b[3])+padding\n",
    "    height = image.shape[1] if (height>image.shape[1]) else height\n",
    "\n",
    "    return image[y0:y0+height , x0:x0+width, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = Path('/media/alessa/Nouveau nom/data/parkar/tests/kaori_nicola')\n",
    "# PATH = Path('/media/alessa/Nouveau nom/data/parkar/tests/alessa')\n",
    "videoframes = list(PATH.iterdir())\n",
    "\n",
    "output_dir = 'withpadd/kaori_nicola'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(720, 1080, 3)\n"
     ]
    }
   ],
   "source": [
    "for frame_path in videoframes:\n",
    "    frame = cv2.imread(str(frame_path))\n",
    "    print(frame.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating networks and loading parameters\n",
      "WARNING:tensorflow:From /home/sohaib/Desktop/Tools/real-time-deep-face-recognition/detect_face.py:210: calling reduce_max (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From /home/sohaib/Desktop/Tools/real-time-deep-face-recognition/detect_face.py:212: calling reduce_sum (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n"
     ]
    }
   ],
   "source": [
    "print('Creating networks and loading parameters')\n",
    "with tf.Graph().as_default():\n",
    "    gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.6)\n",
    "    # sess = tf.Session(config=tf.ConfigProto(gpu_options=gpu_options, log_device_placement=False))\n",
    "    sess = tf.Session(config=tf.ConfigProto(device_count={'GPU': 0}))\n",
    "    with sess.as_default():\n",
    "        threshold = [0.6, 0.7, 0.7]  # three steps's threshold\n",
    "        minsize = 20  # minimum size of face\n",
    "        factor = 0.709  # scale factor\n",
    "        \n",
    "        pnet, rnet, onet = detect_face.create_mtcnn(sess, '/home/sohaib/Desktop/Tools/real-time-deep-face-recognition/det_facenet')\n",
    "\n",
    "        for frame_path in videoframes:\n",
    "            frame = cv2.imread(str(frame_path))\n",
    "            bounding_boxes, _ = detect_face.detect_face(frame, minsize, pnet, rnet, onet, threshold, factor)\n",
    "\n",
    "            nrof_faces = bounding_boxes.shape[0]\n",
    "#             print('Detected_FaceNum: %d' % nrof_faces)        \n",
    "\n",
    "#             ax = show_img(frame)\n",
    "            nr_faces = bounding_boxes.shape[0]\n",
    "            for i in range(nr_faces):\n",
    "                b = bb_hw(bounding_boxes[i])\n",
    "#                 draw_rect(ax, b)\n",
    "                img = crop(frame, i)\n",
    "                crop_name = str(frame_path).split('/')[-1].split('.')[0]\n",
    "                cv2.imwrite(output_dir+'/'+str(crop_name)+'_'+str(i)+'.jpg', img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
